import requests
from requests.auth import HTTPDigestAuth
import datetime
import json
import settings
import re

# Settings:
search_url = settings.AZURE_ENDPOINT
subscription_key = settings.AZURE_SUBSCRIPTION_KEY
search_term = settings.SEARCH_TERM
newsserviceUrl = settings.NEWSSERVICE_ENDPOINT
newsserviceApikey = settings.NEWSSERVICE_APIKEY
freshness = settings.NEWSSERVICE_FRESHNESS
lang = settings.NEWSSERVICE_LANG
region = settings.NEWSSERVICE_REGION
mkt = lang+"-"+region

cvePattern = re.compile(r"(CVE-\d+-\d+)", re.IGNORECASE)
blacklistPattern = re.compile(r"nvd.nist.gov/vuln", re.IGNORECASE)

# Counters:
found=0
stored=0
noCveFound=0
blacklisted=0
responseCodes={}

# uppercase and remove duplicates:
def clean_cves(cves):
  new_cves = [cve.upper() for cve in cves]
  return list(dict.fromkeys(new_cves))


def process_item(item):
  global found, stored, noCveFound, blacklisted, responseCodes

  if (blacklistPattern.search(item["url"])):
    blacklisted += 1
    return

  result = cvePattern.findall(
    item["description"] + item["name"] + item["url"]
  )
  result = clean_cves(result)

  if result:
    print ("Storing article for CVEs: {}".format(result))

    headers = {"api_key": newsserviceApikey}
    data = {
      "cvesMentioned": result,
      "name": item["name"],
      "datePublished": item["datePublished"],
      "dateRetrieved": datetime.datetime.utcnow().isoformat(),
      "description": item["description"],
      "provider": item["provider"][0]["name"],
      "url": item["url"],
      "sourceType": "news",
      "lang": "en",
      "region": "US"
    }
    try:
      response = requests.post(newsserviceUrl, headers=headers, json=data)
      if (response.status_code < 200 or response.status_code>308):
        responseCodes[response.status_code] = responseCodes.get(response.status_code, 0) + 1
        print("HTTP response code {}: {}".format(
          response.status_code, response.content))
      else:
        print("...OK ({})".format(response.status_code))
        stored += 1
    except requests.exceptions.RequestException as e:
      raise SystemExit(e)
  else:
    noCveFound += 1


def main():
  global found
  offset=0 xxx todo: iterate over pages
  print("Running news search: market '{}', freshness '{}', search-term '{}', page 0".format(
    mkt, freshness, search_term
  ))
  headers = {"Ocp-Apim-Subscription-Key": subscription_key}
  params = {"q": search_term,
    "mkt": mkt,
    "category": "ScienceAndTechnology",
    "count": 100,
    "offset": offset,
    "freshness": freshness}
  response = requests.get(search_url, headers=headers, params=params)
  response.raise_for_status()
  search_results = response.json()

  news = json.loads(response.content)
  #print(json.dumps(news, indent=4, sort_keys=True))

  found += len(news["value"])
  print("Found {} articles on page {}.\n".format(
    len(news["value"]), offset
  ))

  for item in news["value"]:
    process_item(item)

  print("\nSummary: \nFound: {}, Stored: {}, Blacklisted: {}, No CVEs found: {}\n".format(
    found, stored, blacklisted, noCveFound))
  if (len(responseCodes)>0):
    print("HTTP error responses (code: count):")
    for code in responseCodes:
      print("{}: {}".format(code, responseCodes[code]))


### Main:
if __name__ == "__main__":
    main()




